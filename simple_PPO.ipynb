{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM3r0wPe5N0K"
      },
      "source": [
        "Solving Package delivery using single-agent PPO with a naive feature representation learning: concatenante all the feature in to a single state vector, and multiple robot actions as a multi discrete distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ro5mHQ3GnN8"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !git clone https://github.com/cuongtv312/marl-delivery.git\n",
        "# %cd marl-delivery\n",
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uWjMBXQoG4JL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "309nvG-V8Otr"
      },
      "outputs": [],
      "source": [
        "from env import Environment\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from env import Environment\n",
        "from ppo_agent import PPOAgent\n",
        "from tqdm import trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_episodes = 500\n",
        "n_robots = 5\n",
        "n_packages = 20\n",
        "max_steps = 2000\n",
        "map_file = \"map3.txt\"\n",
        "\n",
        "# Thông số PPO\n",
        "obs_dim = 454  # 3 (robot) + 5*10 (gói) + 1 (time) + 400 (map 20x20)\n",
        "act_dim = 15   # 5 hướng * 3 hành động\n",
        "agent = PPOAgent(obs_dim, act_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rq1hlk4b8Q37"
      },
      "outputs": [],
      "source": [
        "# TODO: Modify this one to add more information to the Agents\n",
        "def convert_state(state, robot_id, max_pkg=10):\n",
        "    robot = state[\"robots\"][robot_id]\n",
        "    rx, ry, carrying = robot[0] / 20.0, robot[1] / 20.0, robot[2] / 100.0\n",
        "    time = np.array([state[\"time_step\"] / 1000.0], dtype=np.float32)\n",
        "\n",
        "    map_flat = np.array(state[\"map\"], dtype=np.float32).flatten() / 1.0\n",
        "\n",
        "    packages = state[\"packages\"][:max_pkg]\n",
        "    pkg_feats = []\n",
        "    for p in packages:\n",
        "        sx, sy, dx, dy = p[1]/20.0, p[2]/20.0, p[3]/20.0, p[4]/20.0\n",
        "        deadline = p[5] / 1000.0\n",
        "        pkg_feats.extend([sx, sy, dx, dy, deadline])\n",
        "    while len(pkg_feats) < max_pkg * 5:\n",
        "        pkg_feats.append(0.0)\n",
        "\n",
        "    return np.concatenate([[rx, ry, carrying], pkg_feats, time, map_flat])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7SHRHHeF8SjO"
      },
      "outputs": [],
      "source": [
        "# TODO: Modify this one to make the agent learn faster\n",
        "\n",
        "def reward_shaping(r, action):\n",
        "    shaped = r\n",
        "    if action[1] == '1':\n",
        "        shaped += 0.2  # thưởng nhặt\n",
        "    elif action[1] == '2':\n",
        "        shaped += 0.5  # thưởng giao\n",
        "    if action[0] == 'S':\n",
        "        shaped -= 0.01  # phạt đứng yên\n",
        "    return shaped\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reward_shaping(r, action):\n",
        "    shaped = r\n",
        "    if action[1] == '1':\n",
        "        shaped += 0.2  # thưởng nhặt\n",
        "    elif action[1] == '2':\n",
        "        shaped += 0.5  # thưởng giao\n",
        "    if action[0] == 'S':\n",
        "        shaped -= 0.01  # phạt đứng yên\n",
        "    return shaped\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kfrZJa4jG6yE"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'gym' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Avoid to modify the Env class,\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# If it is neccessary, you should describe those changes clearly in report and code\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEnv\u001b[39;00m(\u001b[43mgym\u001b[49m\u001b[38;5;241m.\u001b[39mEnv):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28msuper\u001b[39m(Env, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'gym' is not defined"
          ]
        }
      ],
      "source": [
        "# Avoid to modify the Env class,\n",
        "# If it is neccessary, you should describe those changes clearly in report and code\n",
        "class Env(gym.Env):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(Env, self).__init__()\n",
        "        self.env = Environment(*args, **kwargs)\n",
        "\n",
        "        self.action_space = spaces.multi_discrete.MultiDiscrete([5, 3]*self.env.n_robots)\n",
        "\n",
        "\n",
        "        self.prev_state = self.env.reset()\n",
        "        first_state=convert_state(self.prev_state)\n",
        "        # Define observation space as a dictionary\n",
        "\n",
        "        self.observation_space = spaces.Box(low=0, high=100, shape=first_state.shape, dtype=np.float32)\n",
        "\n",
        "\n",
        "        from sklearn.preprocessing import LabelEncoder\n",
        "        self.le1, self.le2= LabelEncoder(), LabelEncoder()\n",
        "        self.le1.fit(['S', 'L', 'R', 'U', 'D'])\n",
        "        self.le2.fit(['0','1', '2'])\n",
        "\n",
        "    def reset(self, *args, **kwargs):\n",
        "        self.prev_state = self.env.reset()\n",
        "        return convert_state(self.prev_state), {}\n",
        "\n",
        "    def render(self, *args, **kwargs):\n",
        "        return self.env.render()\n",
        "\n",
        "    def step(self, action):\n",
        "        ret = []\n",
        "        ret.append(self.le1.inverse_transform(action.reshape(-1, 2).T[0]))\n",
        "        ret.append(self.le2.inverse_transform(action.reshape(-1, 2).T[1]))\n",
        "        action = list(zip(*ret))\n",
        "\n",
        "        # You should not modify the infos object\n",
        "        s, r, done, infos = self.env.step(action)\n",
        "        new_r = reward_shaping(r, self.env, self.prev_state, action)\n",
        "        self.prev_state = s\n",
        "        return convert_state(s), new_r, \\\n",
        "            done, False, infos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2IQRlqoKl78",
        "outputId": "fc847fe0-d855-43d0-cfe4-159cb2fc43e6"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Env' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvalCallback\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Parallel environments\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m vec_env \u001b[38;5;241m=\u001b[39m \u001b[43mmake_vec_env\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmap2.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_envs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m eval_env \u001b[38;5;241m=\u001b[39m Monitor(Env(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap2.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m10.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m10\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_delivery\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m eval_callback \u001b[38;5;241m=\u001b[39m EvalCallback(eval_env, best_model_save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./best_model/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m                              log_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./logs/\u001b[39m\u001b[38;5;124m\"\u001b[39m, eval_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m,\n\u001b[0;32m     15\u001b[0m                              deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, render\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\trangdo\\.conda\\envs\\myenv3\\Lib\\site-packages\\stable_baselines3\\common\\env_util.py:125\u001b[0m, in \u001b[0;36mmake_vec_env\u001b[1;34m(env_id, n_envs, seed, start_index, monitor_dir, wrapper_class, env_kwargs, vec_env_cls, vec_env_kwargs, monitor_kwargs, wrapper_kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vec_env_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# Default: use a DummyVecEnv\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     vec_env_cls \u001b[38;5;241m=\u001b[39m DummyVecEnv\n\u001b[1;32m--> 125\u001b[0m vec_env \u001b[38;5;241m=\u001b[39m \u001b[43mvec_env_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmake_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_envs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvec_env_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Prepare the seeds for the first reset\u001b[39;00m\n\u001b[0;32m    127\u001b[0m vec_env\u001b[38;5;241m.\u001b[39mseed(seed)\n",
            "File \u001b[1;32mc:\\Users\\trangdo\\.conda\\envs\\myenv3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:31\u001b[0m, in \u001b[0;36mDummyVecEnv.__init__\u001b[1;34m(self, env_fns)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env_fns: \u001b[38;5;28mlist\u001b[39m[Callable[[], gym\u001b[38;5;241m.\u001b[39mEnv]]):\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m_patch_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43menv_fns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mid\u001b[39m(env\u001b[38;5;241m.\u001b[39munwrapped) \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs])) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou tried to create multiple environments, but the function to create them returned the same instance \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead of creating different objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\trangdo\\.conda\\envs\\myenv3\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:31\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env_fns: \u001b[38;5;28mlist\u001b[39m[Callable[[], gym\u001b[38;5;241m.\u001b[39mEnv]]):\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs \u001b[38;5;241m=\u001b[39m [_patch_env(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m env_fns]\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mid\u001b[39m(env\u001b[38;5;241m.\u001b[39munwrapped) \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs])) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou tried to create multiple environments, but the function to create them returned the same instance \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead of creating different objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\trangdo\\.conda\\envs\\myenv3\\Lib\\site-packages\\stable_baselines3\\common\\env_util.py:98\u001b[0m, in \u001b[0;36mmake_vec_env.<locals>.make_env.<locals>._init\u001b[1;34m()\u001b[0m\n\u001b[0;32m     96\u001b[0m         env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(env_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menv_kwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43menv_id\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43menv_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# Patch to support gym 0.21/0.26 and gymnasium\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     env \u001b[38;5;241m=\u001b[39m _patch_env(env)\n",
            "Cell \u001b[1;32mIn[7], line 10\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvalCallback\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Parallel environments\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m vec_env \u001b[38;5;241m=\u001b[39m make_vec_env(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mEnv\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap2.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m10.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m10\u001b[39m), n_envs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     11\u001b[0m eval_env \u001b[38;5;241m=\u001b[39m Monitor(Env(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap2.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m10.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m10\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_delivery\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m eval_callback \u001b[38;5;241m=\u001b[39m EvalCallback(eval_env, best_model_save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./best_model/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m                              log_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./logs/\u001b[39m\u001b[38;5;124m\"\u001b[39m, eval_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m,\n\u001b[0;32m     15\u001b[0m                              deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, render\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Env' is not defined"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "\n",
        "# Parallel environments\n",
        "vec_env = make_vec_env(lambda: Env('map2.txt', 100, 5, 20, -0.01, 10., 1., 10), n_envs=10)\n",
        "eval_env = Monitor(Env('map2.txt', 100, 5, 20, -0.01, 10., 1., 10), \"ppo_delivery\")\n",
        "\n",
        "eval_callback = EvalCallback(eval_env, best_model_save_path=\"./best_model/\",\n",
        "                             log_path=\"./logs/\", eval_freq=5000,\n",
        "                             deterministic=True, render=False)\n",
        "\n",
        "model = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
        "model.learn(total_timesteps=10000, callback=eval_callback)\n",
        "model.save(\"ppo_delivery\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ISQZWTjkyZ6u"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'episodes' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mppo_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PPOAgent\n\u001b[0;32m      2\u001b[0m agent \u001b[38;5;241m=\u001b[39m PPOAgent(obs_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m203\u001b[39m, act_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)  \u001b[38;5;66;03m# sửa số chiều phù hợp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mepisodes\u001b[49m):\n\u001b[0;32m      5\u001b[0m     state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      6\u001b[0m     total_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'episodes' is not defined"
          ]
        }
      ],
      "source": [
        "from ppo_agent import PPOAgent\n",
        "agent = PPOAgent(obs_dim=203, act_dim=15)  # sửa số chiều phù hợp\n",
        "\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        actions = []\n",
        "        log_probs = []\n",
        "        entropies = []\n",
        "        obs_list = []\n",
        "\n",
        "        for i in range(len(state[\"robots\"])):\n",
        "            obs = convert_state(state, i)\n",
        "            action, log_prob, entropy = agent.select_action(obs)\n",
        "            obs_list.append(obs)\n",
        "            actions.append((action // 3, str(action % 3)))  # giải mã action\n",
        "            log_probs.append(log_prob)\n",
        "            entropies.append(entropy)\n",
        "\n",
        "        next_state, rewards, done, info = env.step(actions)\n",
        "\n",
        "        for i in range(len(state[\"robots\"])):\n",
        "            next_obs = convert_state(next_state, i)\n",
        "            r = rewards[i]\n",
        "            agent.store(obs_list[i], actions[i][0] * 3 + int(actions[i][1]), r, next_obs, done, log_probs[i])\n",
        "            total_reward += r\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "    agent.train()\n",
        "    print(f\"Episode {episode} | Reward: {total_reward}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuDtccMk3bXJ",
        "outputId": "3c32669b-9358-49ad-c715-c2ae4e84463c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'total_reward': -3.299999999999999, 'total_time_steps': 100, 'episode': {'r': -3.3, 'l': 100, 't': 168.352014}}\n"
          ]
        }
      ],
      "source": [
        "obs,_ = eval_env.reset()\n",
        "while True:\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, _, info = eval_env.step(action)\n",
        "    #print('='*10)\n",
        "    #eval_env.unwrapped.env.render()\n",
        "    if dones:\n",
        "        break\n",
        "\n",
        "print(info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVpXVAz8Kn9C",
        "outputId": "da85df6f-1219-444b-eeac-0bcf9bd6bf83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'grep' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!pip freeze | grep stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1WfsTHEPzco"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/500 [00:00<?, ?it/s]c:\\Users\\trangdo\\Documents\\HocTap\\TrenLop\\RL\\groupProject\\marl-delivery\\ppo_agent.py:50: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
            "  obs = torch.FloatTensor(obs)\n",
            "  0%|          | 1/500 [00:08<1:07:44,  8.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0 | Total reward: 2117.28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:15<1:05:09,  7.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 1 | Total reward: 2120.58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 3/500 [00:24<1:08:01,  8.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 2 | Total reward: 2133.44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 4/500 [00:32<1:08:42,  8.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 3 | Total reward: 2108.02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 5/500 [00:42<1:11:32,  8.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 4 | Total reward: 2048.57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 6/500 [00:51<1:12:20,  8.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 5 | Total reward: 2035.84\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 7/500 [00:59<1:11:22,  8.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 6 | Total reward: 2037.35\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 8/500 [01:08<1:10:25,  8.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 7 | Total reward: 2056.96\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 9/500 [01:16<1:09:06,  8.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 8 | Total reward: 2011.99\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 10/500 [01:24<1:08:44,  8.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 9 | Total reward: 2068.21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 11/500 [01:32<1:07:53,  8.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 10 | Total reward: 2010.59\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 12/500 [01:41<1:08:11,  8.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 11 | Total reward: 2122.77\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 13/500 [01:48<1:05:53,  8.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 12 | Total reward: 2115.40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 14/500 [01:56<1:04:56,  8.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 13 | Total reward: 2096.59\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 15/500 [02:04<1:03:40,  7.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 14 | Total reward: 2090.88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 16/500 [02:11<1:03:22,  7.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 15 | Total reward: 2064.34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 17/500 [02:19<1:02:20,  7.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 16 | Total reward: 2071.03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▎         | 18/500 [02:26<1:01:41,  7.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 17 | Total reward: 2077.92\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 19/500 [02:34<1:01:43,  7.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 18 | Total reward: 2079.03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 20/500 [02:42<1:01:04,  7.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 19 | Total reward: 2056.01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 21/500 [02:49<1:01:00,  7.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 20 | Total reward: 2029.15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 22/500 [02:57<1:00:22,  7.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 21 | Total reward: 2060.31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 23/500 [03:04<1:00:44,  7.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 22 | Total reward: 2045.58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 24/500 [03:12<1:00:24,  7.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 23 | Total reward: 2074.88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 25/500 [03:20<1:00:32,  7.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 24 | Total reward: 2059.09\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 26/500 [03:27<1:00:23,  7.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 25 | Total reward: 2086.08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 27/500 [03:35<1:00:30,  7.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 26 | Total reward: 2087.61\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 28/500 [03:43<59:51,  7.61s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 27 | Total reward: 2028.88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 29/500 [03:50<59:21,  7.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 28 | Total reward: 2089.44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 30/500 [03:58<59:32,  7.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 29 | Total reward: 2058.58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 31/500 [04:05<59:16,  7.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 30 | Total reward: 2008.25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▋         | 32/500 [04:13<59:33,  7.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 31 | Total reward: 2033.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 33/500 [04:21<59:23,  7.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 32 | Total reward: 2065.18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 34/500 [04:29<1:01:00,  7.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 33 | Total reward: 2062.68\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 35/500 [04:37<1:01:50,  7.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 34 | Total reward: 2121.44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 36/500 [04:45<1:01:32,  7.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 35 | Total reward: 2044.79\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 37/500 [04:53<1:01:00,  7.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 36 | Total reward: 2086.05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 38/500 [05:01<1:01:05,  7.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 37 | Total reward: 2155.96\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 39/500 [05:09<1:00:19,  7.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 38 | Total reward: 1991.93\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 40/500 [05:16<59:51,  7.81s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 39 | Total reward: 2065.34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 41/500 [05:25<1:01:10,  8.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 40 | Total reward: 2064.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 42/500 [05:32<1:00:20,  7.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 41 | Total reward: 2040.16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 43/500 [05:41<1:00:30,  7.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 42 | Total reward: 2043.60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 44/500 [05:48<59:39,  7.85s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 43 | Total reward: 2081.26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 45/500 [05:56<59:35,  7.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 44 | Total reward: 2043.37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 46/500 [06:04<59:00,  7.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 45 | Total reward: 2027.02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 47/500 [06:12<59:06,  7.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 46 | Total reward: 2028.60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|▉         | 48/500 [06:19<58:40,  7.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 47 | Total reward: 2121.16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|▉         | 49/500 [06:27<59:00,  7.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 48 | Total reward: 2085.38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 50/500 [06:35<59:12,  7.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 49 | Total reward: 2030.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 51/500 [06:43<58:37,  7.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 50 | Total reward: 2043.14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 52/500 [06:51<58:48,  7.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 51 | Total reward: 2030.76\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 53/500 [06:59<1:00:01,  8.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 52 | Total reward: 2095.62\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 54/500 [07:07<59:36,  8.02s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 53 | Total reward: 2010.86\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 55/500 [07:15<58:41,  7.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 54 | Total reward: 2056.83\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 56/500 [07:23<58:36,  7.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 55 | Total reward: 2042.01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█▏        | 57/500 [07:31<58:02,  7.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 56 | Total reward: 2090.46\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 58/500 [07:39<58:43,  7.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 57 | Total reward: 2078.76\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 59/500 [07:47<57:54,  7.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 58 | Total reward: 2048.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 60/500 [07:54<57:24,  7.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 59 | Total reward: 2034.74\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 61/500 [08:02<57:22,  7.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 60 | Total reward: 2045.96\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 62/500 [08:10<56:53,  7.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 61 | Total reward: 2084.29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 63/500 [08:18<56:57,  7.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 62 | Total reward: 2070.06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 64/500 [08:25<56:27,  7.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 63 | Total reward: 2045.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 65/500 [08:33<56:33,  7.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 64 | Total reward: 2090.40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 66/500 [08:41<56:48,  7.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 65 | Total reward: 2062.34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 67/500 [08:49<56:48,  7.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 66 | Total reward: 1982.62\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▎        | 68/500 [08:57<56:12,  7.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 67 | Total reward: 2054.59\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 69/500 [09:05<56:21,  7.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 68 | Total reward: 2050.97\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 70/500 [09:12<55:51,  7.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 69 | Total reward: 2046.96\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 71/500 [09:20<55:28,  7.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 70 | Total reward: 2052.47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 72/500 [09:28<55:37,  7.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 71 | Total reward: 2081.06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 73/500 [09:36<55:15,  7.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 72 | Total reward: 2061.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 74/500 [09:44<55:51,  7.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 73 | Total reward: 2043.74\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 75/500 [09:52<55:40,  7.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 74 | Total reward: 2034.44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 76/500 [09:59<55:32,  7.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 75 | Total reward: 2028.64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 77/500 [10:07<55:08,  7.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 76 | Total reward: 2092.39\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 78/500 [10:15<55:12,  7.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 77 | Total reward: 2042.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 79/500 [10:23<54:40,  7.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 78 | Total reward: 2067.91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 80/500 [10:31<54:43,  7.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 79 | Total reward: 2083.85\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 81/500 [10:38<54:15,  7.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 80 | Total reward: 2047.05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▋        | 82/500 [10:46<54:28,  7.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 81 | Total reward: 2045.19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 83/500 [10:54<54:27,  7.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 82 | Total reward: 2107.82\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 84/500 [11:02<54:26,  7.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 83 | Total reward: 2020.75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 85/500 [11:10<54:24,  7.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 84 | Total reward: 2035.33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 86/500 [11:18<53:48,  7.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 85 | Total reward: 2140.79\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 87/500 [11:25<53:51,  7.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 86 | Total reward: 2076.85\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 88/500 [11:33<53:32,  7.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 87 | Total reward: 2039.52\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 89/500 [11:41<53:45,  7.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 88 | Total reward: 2096.29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 90/500 [11:49<53:04,  7.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 89 | Total reward: 2069.02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 91/500 [11:57<53:52,  7.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 90 | Total reward: 2011.56\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 92/500 [12:05<53:20,  7.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 91 | Total reward: 2132.56\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▊        | 93/500 [12:12<52:52,  7.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 92 | Total reward: 2026.53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 94/500 [12:20<53:00,  7.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 93 | Total reward: 2054.57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 95/500 [12:28<52:30,  7.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 94 | Total reward: 2073.09\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 96/500 [12:36<52:38,  7.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 95 | Total reward: 2055.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 97/500 [12:43<52:07,  7.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 96 | Total reward: 2066.56\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 98/500 [12:51<52:16,  7.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 97 | Total reward: 2074.36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 99/500 [12:59<51:52,  7.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 98 | Total reward: 2048.83\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 100/500 [13:07<52:56,  7.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 99 | Total reward: 2069.45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 101/500 [13:15<52:31,  7.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 100 | Total reward: 2114.54\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 102/500 [13:23<53:01,  7.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 101 | Total reward: 2058.49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 103/500 [13:31<52:24,  7.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 102 | Total reward: 2053.29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 104/500 [13:39<51:47,  7.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 103 | Total reward: 2010.53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 105/500 [13:47<51:50,  7.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 104 | Total reward: 2058.02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 106/500 [13:55<51:38,  7.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 105 | Total reward: 2071.29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 107/500 [14:03<52:06,  7.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 106 | Total reward: 2037.91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 108/500 [14:11<52:45,  8.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 107 | Total reward: 2059.95\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 109/500 [14:19<53:15,  8.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 108 | Total reward: 2028.07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 110/500 [14:27<52:44,  8.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 109 | Total reward: 2034.41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 111/500 [14:36<53:08,  8.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 110 | Total reward: 2067.93\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 112/500 [14:44<52:32,  8.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 111 | Total reward: 2031.11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 113/500 [14:52<52:06,  8.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 112 | Total reward: 2041.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 114/500 [15:00<52:03,  8.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 113 | Total reward: 2075.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 115/500 [15:09<52:56,  8.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 114 | Total reward: 2028.06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 116/500 [15:17<53:20,  8.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 115 | Total reward: 2103.68\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 117/500 [15:25<52:40,  8.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 116 | Total reward: 2028.09\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▎       | 118/500 [15:34<53:24,  8.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 117 | Total reward: 2067.95\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 119/500 [15:43<54:41,  8.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 118 | Total reward: 2135.44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 120/500 [15:52<56:09,  8.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 119 | Total reward: 2065.75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 121/500 [16:02<57:11,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 120 | Total reward: 2051.64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 122/500 [16:11<58:02,  9.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 121 | Total reward: 2029.77\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 123/500 [16:22<59:26,  9.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 122 | Total reward: 2043.25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 124/500 [16:30<57:34,  9.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 123 | Total reward: 2032.04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 125/500 [16:38<55:40,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 124 | Total reward: 2060.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 126/500 [16:46<53:51,  8.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 125 | Total reward: 2061.70\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 127/500 [16:55<52:59,  8.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 126 | Total reward: 2126.33\n"
          ]
        }
      ],
      "source": [
        "for ep in trange(num_episodes):\n",
        "    env = Environment(map_file=map_file, max_time_steps=max_steps,\n",
        "                      n_robots=n_robots, n_packages=n_packages)\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        actions = []\n",
        "        log_probs = []\n",
        "        obs_list = []\n",
        "\n",
        "        for i in range(n_robots):\n",
        "            obs = convert_state(state, i)\n",
        "            act_flat, log_prob, _ = agent.select_action(obs)\n",
        "            move = ['S', 'L', 'R', 'U', 'D'][act_flat // 3]\n",
        "            act = str(act_flat % 3)\n",
        "            actions.append((move, act))\n",
        "            obs_list.append(obs)\n",
        "            log_probs.append(log_prob)\n",
        "\n",
        "        next_state, reward, done, infos = env.step(actions)\n",
        "\n",
        "        for i in range(n_robots):\n",
        "            shaped_reward = reward_shaping(reward, actions[i])  \n",
        "            next_obs = convert_state(next_state, i)\n",
        "            flat_action = ['S', 'L', 'R', 'U', 'D'].index(actions[i][0]) * 3 + int(actions[i][1])\n",
        "            agent.store(obs_list[i], flat_action, shaped_reward, next_obs, done, log_probs[i])\n",
        "            total_reward += shaped_reward\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "    agent.train()\n",
        "    print(f\"Episode {ep} | Total reward: {total_reward:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
